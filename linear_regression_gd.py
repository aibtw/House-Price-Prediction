import csv
import numpy as np
from numpy import random as rnd
from matplotlib import pyplot as plt


def main():
    # ---------------------- Read input ---------------------- #
    x = np.transpose(np.loadtxt("train.csv",
                                delimiter=',',
                                skiprows=1,
                                usecols=(1, 4, 17, 18, 19, 43, 44, 46, 62, 77)))  # use only the specified columns
    y = np.loadtxt("train.csv",
                   delimiter=',',
                   skiprows=1,
                   usecols=-1)

    (x_m, x_n) = x.shape  # The dimensions of x are [m rows by n columns]
    num_of_features = x_m

    # for i in x:
    #     print(i)
    # print(y)

    # ---------------------- Feature Scaling ---------------------- #
    s_factor = np.amax(x, axis=1)
    x = x / s_factor[:, None]

    # ---------------------- Arbitrary example for debugging ---------------------- #
    # x = np.arange(-10, 10, 0.1)
    # (x_m, x_n) = np.asmatrix(x).shape  # The dimensions of x are m rows by n columns
    # num_of_features = x_m
    # y = 3 * x - 5 + (1 * rnd.random(x_n))  # Theta 0 = -5. Theta 1 = 3.

    # --------- Theta random start point.   Thetas = [Th0, Th1, Th2 ...] --------- #
    thetas = rnd.random(num_of_features + 1)
    # thetas = np.ones(num_of_features + 1)
    # print(thetas)

    # ---------------------- Learning rate ---------------------- #
    lr = 0.005

    # ---------------------- Initialize loss ---------------------- #
    loss = list()

    # ---------------------- Manipulate input data for processing ---------------------- #
    """ trainX = [1 , 1,  1  ... ] <--- To be multiplied by Theta0
                 [x1, x2, x3 ... ] <--- Feature 1, multiplies by Theta1
                 [v1, v2, v3 ... ] <--- Feature 2, multiplied by Theta2
                 ... etc
    """
    trainX = np.vstack([np.ones(x_n), x])
    """ trainY = [Y1 , Y2,  Y3  ... ] """
    trainY = y

    # ==================== Main loop ==================== #
    for i in range(10000):
        """ hypothesis hyp = [h1 , h2,  h3  ... ]. (This is the guess generated by current value of theta)"""
        hyp = np.dot(thetas, trainX)
        # print(hyp)

        """Calculate loss"""
        loss.append(np.sum((hyp - trainY) ** 2) / x_n)
        # print(loss)


        """Update function = trainX * loss function"""
        # print(np.vstack(hyp - trainY))
        Grad = np.dot(trainX, np.vstack(hyp - trainY) / x_n)
        # Grad = np.dot(trainX, np.asmatrix(hyp - trainY).transpose() / x_n) # Wrong
        # print(Grad)
        """Theoretically Correct"""

        """Update theta"""
        # thetas = thetas - lr * Grad.reshape(1, thetas.size)
        thetas = thetas - (lr * np.hstack(Grad))
        # print(thetas)
        """Theoretically correct"""

        # print(thetas)
        relative_loss = abs((loss[i] - loss[i - 1]) / loss[i] * 100)
        if relative_loss <= 0.01 and i != 0:
            print(i)
            break
        plt.plot(loss)
        # plt.pause(0.0001)

    print(thetas)
    plt.show()


if __name__ == "__main__":
    main()
