import csv
import sys
import numpy as np
from numpy import random as rnd
from matplotlib import pyplot as plt


def main():
    # ---------------------- Read input ---------------------- #
    x = np.transpose(np.loadtxt("train.csv",
                                delimiter=',',
                                skiprows=1,
                                usecols=(1, 4, 17, 18, 19, 43, 44, 46, 62, 77)))  # use only the specified columns
    y = np.loadtxt("train.csv",
                   delimiter=',',
                   skiprows=1,
                   usecols=-1)

    (x_m, x_n) = x.shape  # The dimensions of x are [m rows by n columns]
    num_of_features = x_m

    # ---------------------- Feature Scaling ---------------------- #
    s_factor = np.amax(x, axis=1)
    x = x / s_factor[:, None]

    # ---------------------- Arbitrary example for debugging ---------------------- #
    # x = np.arange(-10, 10, 0.1)
    # (x_m, x_n) = np.asmatrix(x).shape  # The dimensions of x are m rows by n columns
    # num_of_features = x_m
    # y = 3 * x - 5 + (1 * rnd.random(x_n))  # Theta 0 = -5. Theta 1 = 3.

    # --------- Theta random start point.   Thetas = [Th0, Th1, Th2 ...] --------- #
    thetas = rnd.random(num_of_features + 1)
    # thetas = np.ones(num_of_features + 1)
    # ---------------------- Learning rate ---------------------- #
    lr = 0.005
    # ---------------------- Initialize loss ---------------------- #
    loss = list()
    # ---------------------- Manipulate input data for processing ---------------------- #
    """ trainX = [1 , 1,  1  ... ] <--- To be multiplied by Theta0
                 [x1, x2, x3 ... ] <--- Feature 1, multiplies by Theta1
                 [v1, v2, v3 ... ] <--- Feature 2, multiplied by Theta2
                 ... etc
    """
    trainX = np.vstack([np.ones(x_n), x])
    """ trainY = [Y1 , Y2,  Y3  ... ] """
    trainY = y

    # ==================== Main loop ==================== #
    for i in range(10000):
        """ hypothesis hyp = [h1 , h2,  h3  ... ]. (This is the guess generated by current value of theta)"""
        hyp = np.dot(thetas, trainX)

        """Calculate loss"""
        loss.append(np.sum((hyp - trainY) ** 2) / x_n)

        """Update function = trainX * loss function"""
        Grad = np.dot(trainX, np.vstack(hyp - trainY) / x_n)
        """Theoretically Correct"""

        """Update theta"""
        thetas = thetas - (lr * np.hstack(Grad))
        """Theoretically correct"""

        relative_loss = abs((loss[i] - loss[i - 1]) / loss[i] * 100)
        if relative_loss <= 0.01 and i != 0:
            break
        plt.plot(loss)
        # plt.pause(0.0001)

    # Output Area
    print(thetas)
    np.save('linear_thetas', thetas)  # Save thetas for the test phase.
    with open('Linear_Train_Results.txt', 'w') as wr:
        wr.write("The loss value for train model is: \n" + str(loss[-1]))
        wr.write("\nThe Theta values for training model are: \n")
        wr.write(np.array2string(thetas))
    plt.show()


# ===================================================================================================== #
# ===========================================  Testing  =============================================== #
# ===================================================================================================== #
def test():
    print("Testing:")

    # Reading input
    train_thetas = np.load("linear_thetas.npy")
    x = np.transpose(np.genfromtxt("test.csv", delimiter=',', skip_header=1,
                                   usecols=(1, 4, 17, 18, 19, 43, 44, 46, 62, 77),  # use only the specified columns
                                   filling_values=0))
    y = np.loadtxt("test.csv", delimiter=',', skiprows=1, usecols=-1)

    # Feature Scaling
    s_factor = np.amax(x, axis=1)
    x = x / s_factor[:, None]

    # Dimensions
    (x_m, x_n) = x.shape

    print("X and Y: ")
    print(y)
    print(x)

    testX = np.vstack([np.ones(x_n), x])
    testY = y
    hyp = np.dot(train_thetas, testX)
    print("HYPOTHESIS: \n")
    print(hyp)
    test_loss = np.sum((hyp - testY) ** 2) / x_n
    print("Linear Test Loss is: " + str(test_loss))


if __name__ == "__main__":
    if (sys.argv[1] == "T"):
        main()
    elif (sys.argv[1] == "V"):
        test()
    else:
        print("wrong command line argument")
        exit()
